import random
from nlp import TextPreprocessor, is_similar
from nltk import edit_distance
from sklearn.pipeline import Pipeline
from typing import Dict, List, Any, Union, Optional
from dialogues import Dialogues
from constants import THEME_HISTORY_LENGTH

def get_response_by_message_text(
    message_text: str, 
    pipeline: Pipeline, 
    intents_data: Dict[str, dict],
    dialogues: Dialogues,
    theme_history: List[str]
) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""

    intent = classify_intent(
        message_text,
        pipeline,
        intents_data['intents'],
        theme_history
    )

    if intent:
        responses = intents_data['intents'].get(intent, {}).get('responses')
        if responses:
            return get_random_response(responses)

    return generate_answer(message_text, dialogues) or get_random_failure_phrase(intents_data['failure_phrases'])

def classify_intent(
    message_text: str, 
    pipeline: Pipeline, 
    intents: Dict, 
    theme_history
) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∏—Å—Ç–æ—Ä–∏–∏ —Ç–µ–º."""

    for i, theme in enumerate(theme_history):
        intent = classify_intent_by_theme(message_text, pipeline, intents, theme)
        if intent:
            if i > 0:
                theme_history[:] = theme_history[i:]
            break
    else:
        # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ —Ç–µ–º–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞, –ø—Ä–æ–±—É–µ–º –±–µ–∑ —Ç–µ–º—ã
        intent = classify_intent_by_theme(message_text, pipeline, intents)

    if intent:
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –∏–Ω—Ç–µ–Ω—Ç –æ–ø—Ä–µ–¥–µ–ª—ë–Ω –∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å —Ç–µ–º–∞
        theme = intents[intent].get('theme_gen')
        if theme and theme not in theme_history:
            theme_history.insert(0, theme)
            if len(theme_history) > THEME_HISTORY_LENGTH:
                theme_history.pop()
    else:
        # –ï—Å–ª–∏ –∏–Ω—Ç–µ–Ω—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω ‚Äî –æ—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ç–µ–º
        theme_history.clear()

    return intent

def classify_intent_by_theme(message_text: str, pipeline: Pipeline, intents: Dict, theme=None):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ —Ç–µ–º–µ."""

    text_preprocessor = TextPreprocessor()
    cleaned_text = text_preprocessor.clear_phrase(message_text)

    def is_theme_match(theme_app):
        return (
            theme_app is None and theme is None or
            theme_app and (theme in theme_app or '*' in theme_app)
        )
    
    def is_similar_to_examples(intent_data):
        return any(
            is_similar(cleaned_text, text_preprocessor.clear_phrase(example))
            for example in intent_data.get('examples', [])
        )

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–Ω—Ç–∞
    predicted_intent = pipeline.predict([cleaned_text])[0]
    intent_data = intents.get(predicted_intent)
    if intent_data and is_theme_match(intent_data.get('theme_app')) and is_similar_to_examples(intent_data):
        return predicted_intent

    # 2. –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –¥—Ä—É–≥–∏–º –∏–Ω—Ç–µ–Ω—Ç–∞–º
    for intent, intent_data in intents.items():
        if is_theme_match(intent_data.get('theme_app')) and is_similar_to_examples(intent_data):
            return intent

    return None

def generate_answer(message_text: str, dialogues: Dialogues) -> Union[Any, None]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤."""

    text_preprocessor = TextPreprocessor()
    cleaned_text = text_preprocessor.clear_phrase(message_text)
    words = set(cleaned_text.split())

    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø–∞—Ä—ã (–≤–æ–ø—Ä–æ—Å, –æ—Ç–≤–µ—Ç), –∏—Å–∫–ª—é—á–∞—è –ø–æ–≤—Ç–æ—Ä—ã
    mini_dataset = {
        tuple(pair) for word in words if word in dialogues for pair in dialogues[word]
    }

    candidates = []
    for question, answer in mini_dataset:
        if abs(len(cleaned_text) - len(question)) / len(question) < 0.2:
            distance = edit_distance(cleaned_text, question)
            distance_weighted = distance / len(question)
            if distance_weighted < 0.2:
                candidates.append((distance_weighted, question, answer))

    return min(candidates, key=lambda x: x[0])[2] if candidates else None

def get_random_response(responses: List[str]) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ –ø–æ–ª—è 'responses' –æ–±—ä–µ–∫—Ç–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è."""
    return random.choice(responses)

def get_random_failure_phrase(failure_phrases: List[str]) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é —Ñ—Ä–∞–∑—É –∏–∑ –º–∞—Å—Å–∏–≤–∞ 'failure_phrases'."""
    return random.choice(failure_phrases)

def get_book_recommendations(book_ads: Dict, genre: Optional[str] = None) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–Ω–∏–≥ –ø–æ –∂–∞–Ω—Ä—É –∏–ª–∏ —Å–ª—É—á–∞–π–Ω–æ–º—É –∂–∞–Ω—Ä—É, –µ—Å–ª–∏ –∂–∞–Ω—Ä –Ω–µ —É–∫–∞–∑–∞–Ω."""

    if not genre or genre not in book_ads:
        available_genres = list(book_ads.keys())
        if not available_genres:
            return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —Å–µ–π—á–∞—Å –Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."
        genre = random.choice(available_genres)

    books = book_ads.get(genre, [])
    if not books:
        return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —Å–µ–π—á–∞—Å –Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."

    response = "–í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ç–ª–∏—á–Ω—ã—Ö –∫–Ω–∏–≥:\n\n"
    for book in books[:3]:
        response += (
            f"üìñ <b>{book['title']}</b>\n"
            f"   {book['description']}\n"
            f"   –¶–µ–Ω–∞: {book['price']}\n\n"
        )
    response += "–•–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ –∫–∞–∫–æ–π-—Ç–æ –∏–∑ –Ω–∏—Ö?"
    return response
