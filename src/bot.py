import random
from nlp import TextPreprocessor, is_similar
from nltk import edit_distance
from sklearn.pipeline import Pipeline
from typing import Dict, List, Any, Union, Optional
from dialogues import Dialogues
from constants import THEME_HISTORY_LENGTH

def get_response_by_message_text(
    message_text: str, 
    pipeline: Pipeline, 
    intents_data: Dict[str, dict],
    dialogues: Dialogues,
    theme_history: List[str],
    book_ads: Dict[str, list]
) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""

    intent = classify_intent(
        message_text,
        pipeline,
        intents_data['intents'],
        theme_history
    )

    if intent:
        responses = intents_data['intents'].get(intent, {}).get('responses')
        if responses:
            return get_random_response(responses)
    
    book_result = handle_book_query(book_ads, message_text)
    if (book_result):
        return book_result

    return generate_answer(message_text, dialogues) or get_random_failure_phrase(intents_data['failure_phrases'])

def classify_intent(
    message_text: str, 
    pipeline: Pipeline, 
    intents: Dict, 
    theme_history
) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∏—Å—Ç–æ—Ä–∏–∏ —Ç–µ–º."""

    for i, theme in enumerate(theme_history):
        intent = classify_intent_by_theme(message_text, pipeline, intents, theme)
        if intent:
            if i > 0:
                theme_history[:] = theme_history[i:]
            break
    else:
        # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ —Ç–µ–º–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞, –ø—Ä–æ–±—É–µ–º –±–µ–∑ —Ç–µ–º—ã
        intent = classify_intent_by_theme(message_text, pipeline, intents)

    if intent:
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –∏–Ω—Ç–µ–Ω—Ç –æ–ø—Ä–µ–¥–µ–ª—ë–Ω –∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å —Ç–µ–º–∞
        theme = intents[intent].get('theme_gen')
        if theme and theme not in theme_history:
            theme_history.insert(0, theme)
            if len(theme_history) > THEME_HISTORY_LENGTH:
                theme_history.pop()
    else:
        # –ï—Å–ª–∏ –∏–Ω—Ç–µ–Ω—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω ‚Äî –æ—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ç–µ–º
        theme_history.clear()

    return intent

def handle_book_query(book_ads: Dict[str, List[Dict]], message_text: str) -> str:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ –∫–Ω–∏–≥–µ, –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ—Ö–æ–∂–∞—è."""
    
    text_preprocessor = TextPreprocessor()
    cleaned_text = text_preprocessor.clear_phrase(message_text)
    candidates = []

    # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –≤–≤–æ–¥–∞
    if len(cleaned_text) < 4:
        return None

    for genre_books in book_ads.values():
        for book in genre_books:
            title = book.get("title", "")
            cleaned_title = text_preprocessor.clear_phrase(title)

            # –ü–æ–¥—Å—Ç—Ä–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚Äî –ø—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –¥–ª–∏–Ω–µ
            if len(cleaned_text) >= 5 and cleaned_text in cleaned_title:
                candidates.append((0.0, title))
                continue

            # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞
            if abs(len(cleaned_text) - len(cleaned_title)) / max(len(cleaned_title), 1) < 0.3:
                dist = edit_distance(cleaned_text, cleaned_title)
                score = dist / max(len(cleaned_title), 1)

                if score < 0.3:  # –¥–æ–ø—É—Å—Ç–∏–º—ã–π —É—Ä–æ–≤–µ–Ω—å "–ø–æ—Ö–æ–∂–µ—Å—Ç–∏"
                    candidates.append((score, title))

    if not candidates:
        return None

    best_match = sorted(candidates, key=lambda x: x[0])[0]
    if best_match[0] > 0.25:  # –¥–∞–∂–µ –ª—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–ª–∏–∑–æ–∫
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Ç–æ—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–Ω–∏–≥—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å."

    return get_book_details(book_ads, best_match[1])
    
def classify_intent_by_theme(message_text: str, pipeline: Pipeline, intents: Dict, theme=None):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ —Ç–µ–º–µ."""

    text_preprocessor = TextPreprocessor()
    cleaned_text = text_preprocessor.clear_phrase(message_text)

    def is_theme_match(theme_app):
        return (
            theme_app is None and theme is None or
            theme_app and (theme in theme_app or '*' in theme_app)
        )
    
    def is_similar_to_examples(intent_data):
        return any(
            is_similar(cleaned_text, text_preprocessor.clear_phrase(example))
            for example in intent_data.get('examples', [])
        )

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–Ω—Ç–∞
    predicted_intent = pipeline.predict([cleaned_text])[0]
    intent_data = intents.get(predicted_intent)
    if intent_data and is_theme_match(intent_data.get('theme_app')) and is_similar_to_examples(intent_data):
        return predicted_intent

    # 2. –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –¥—Ä—É–≥–∏–º –∏–Ω—Ç–µ–Ω—Ç–∞–º
    for intent, intent_data in intents.items():
        if is_theme_match(intent_data.get('theme_app')) and is_similar_to_examples(intent_data):
            return intent

    return None

def generate_answer(message_text: str, dialogues: Dialogues) -> Union[Any, None]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤."""

    text_preprocessor = TextPreprocessor()
    cleaned_text = text_preprocessor.clear_phrase(message_text)
    words = set(cleaned_text.split())

    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø–∞—Ä—ã (–≤–æ–ø—Ä–æ—Å, –æ—Ç–≤–µ—Ç), –∏—Å–∫–ª—é—á–∞—è –ø–æ–≤—Ç–æ—Ä—ã
    mini_dataset = {
        tuple(pair) for word in words if word in dialogues for pair in dialogues[word]
    }

    candidates = []
    for question, answer in mini_dataset:
        if abs(len(cleaned_text) - len(question)) / len(question) < 0.2:
            distance = edit_distance(cleaned_text, question)
            distance_weighted = distance / len(question)
            if distance_weighted < 0.2:
                candidates.append((distance_weighted, question, answer))

    return min(candidates, key=lambda x: x[0])[2] if candidates else None

def get_random_response(responses: List[str]) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ –ø–æ–ª—è 'responses' –æ–±—ä–µ–∫—Ç–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è."""
    return random.choice(responses)

def get_random_failure_phrase(failure_phrases: List[str]) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é —Ñ—Ä–∞–∑—É –∏–∑ –º–∞—Å—Å–∏–≤–∞ 'failure_phrases'."""
    return random.choice(failure_phrases)

def get_book_recommendations(book_ads: Dict, genre: Optional[str] = None) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–Ω–∏–≥ –ø–æ –∂–∞–Ω—Ä—É –∏–ª–∏ —Å–ª—É—á–∞–π–Ω–æ–º—É –∂–∞–Ω—Ä—É, –µ—Å–ª–∏ –∂–∞–Ω—Ä –Ω–µ —É–∫–∞–∑–∞–Ω."""

    if not genre or genre not in book_ads:
        available_genres = list(book_ads.keys())
        if not available_genres:
            return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —Å–µ–π—á–∞—Å –Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."
        genre = random.choice(available_genres)

    books = book_ads.get(genre, [])
    if not books:
        return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —Å–µ–π—á–∞—Å –Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."

    response = "–í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ç–ª–∏—á–Ω—ã—Ö –∫–Ω–∏–≥:\n\n"
    for book in books[:3]:
        response += (
            f"üìñ <b>{book['title']}</b>\n"
            f"   {book['description']}\n"
            f"   –¶–µ–Ω–∞: {book['price']}\n\n"
        )
    response += "–•–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ –∫–∞–∫–æ–π-—Ç–æ –∏–∑ –Ω–∏—Ö?"
    return response

def get_book_details(book_ads: Dict[str, list], title: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–Ω–∏–≥–µ –ø–æ –µ—ë –Ω–∞–∑–≤–∞–Ω–∏—é."""

    for genre, books in book_ads.items():
        for book in books:
            if book.get("title", "").lower() == title.lower():
                details = (
                    f"üìö <b>{book['title']}</b>\n"
                    f"–ê–≤—Ç–æ—Ä: {book.get('author', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
                    f"–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è: {book.get('year', '‚Äî')}\n"
                    f"–†–µ–π—Ç–∏–Ω–≥: {book.get('rating', '‚Äî')}/5\n"
                    f"–°—Ç—Ä–∞–Ω–∏—Ü: {book.get('pages', '‚Äî')}\n"
                    f"ISBN: {book.get('isbn', '‚Äî')}\n"
                    f"–¶–µ–Ω–∞: {book.get('price', '‚Äî')}\n"
                    f"–û–ø–∏—Å–∞–Ω–∏–µ: {book.get('description', '‚Äî')}\n"
                )

                # –î–æ–±–∞–≤–∏–º —Ü–∏—Ç–∞—Ç—É, –µ—Å–ª–∏ –µ—Å—Ç—å
                if book.get("quotes"):
                    details += f"\nüí¨ –¶–∏—Ç–∞—Ç–∞: ¬´{book['quotes'][0]}¬ª"

                # –ü–æ—Ö–æ–∂–∏–µ –∫–Ω–∏–≥–∏
                if book.get("similar"):
                    details += f"\nüìñ –ü–æ—Ö–æ–∂–∏–µ –∫–Ω–∏–≥–∏: {', '.join(book['similar'])}"

                return details

    return "–ö–Ω–∏–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ —É–∫–∞–∑–∞–Ω–æ —Ç–æ—á–Ω–æ."
